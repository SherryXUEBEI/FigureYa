#!/usr/bin/env python3
"""
GitHub Pageså…¼å®¹çš„æ™ºè°±AI RAGåç«¯æœåŠ¡
å¯ä»¥é€šè¿‡GitHub Actionséƒ¨ç½²ï¼Œæä¾›AIæœç´¢API
"""

import os
import json
import sys
from pathlib import Path
from typing import Dict, List
import urllib.parse
from http.server import HTTPServer, BaseHTTPRequestHandler
from dataclasses import dataclass
import subprocess

# æ¨¡æ‹Ÿæ™ºè°±AI SDK (å¦‚æœåœ¨GitHub Pagesç¯å¢ƒä¸­å¯èƒ½æ— æ³•å®‰è£…çœŸå®SDK)
class MockZhipuAI:
    def __init__(self, api_key: str):
        self.api_key = api_key

    def chat(self, messages: List[Dict], **kwargs):
        """æ¨¡æ‹ŸèŠå¤©å®Œæˆ"""
        # æ¨¡æ‹ŸAPIå»¶è¿Ÿ
        import time
        time.sleep(1)

        # è·å–ç”¨æˆ·æ¶ˆæ¯
        user_message = ""
        for msg in messages:
            if msg.get("role") == "user":
                user_message = msg.get("content", "")
                break

        # ç”Ÿæˆæ¨¡æ‹Ÿå›å¤
        response_text = self._generate_mock_response(user_message)

        return MockCompletion(response_text)

    def _generate_mock_response(self, query: str) -> str:
        """ç”Ÿæˆæ¨¡æ‹Ÿå›å¤"""
        responses = {
            "RNA-seq": """åŸºäºæ‚¨çš„æŸ¥è¯¢ï¼Œæˆ‘æ¨èä½¿ç”¨**FigureYa59volcanoV2**æ¨¡å—è¿›è¡ŒRNA-seqå·®å¼‚è¡¨è¾¾åˆ†æã€‚

ğŸ¯ **æ¨èç†ç”±**ï¼š
â€¢ ç«å±±å›¾æ˜¯æœ€ç›´è§‚çš„å·®å¼‚è¡¨è¾¾åŸºå› å¯è§†åŒ–æ–¹æ³•
â€¢ èƒ½å¤ŸåŒæ—¶å±•ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§å’Œç”Ÿç‰©å­¦æ„ä¹‰
â€¢ æ”¯æŒDESeq2ã€edgeRã€limmaç­‰å¤šç§åˆ†ææ–¹æ³•

ğŸ“Š **åˆ†ææ­¥éª¤**ï¼š
1. æ•°æ®é¢„å¤„ç†å’Œè´¨é‡æ§åˆ¶
2. ä½¿ç”¨DESeq2è¿›è¡Œå·®å¼‚è¡¨è¾¾åˆ†æ
3. è®¾ç½®åˆé€‚çš„é˜ˆå€¼ï¼ˆpvalue < 0.05, |logFC| > 1ï¼‰
4. ç”Ÿæˆç«å±±å›¾è¿›è¡Œç»“æœå¯è§†åŒ–

ğŸ’¡ **å‚æ•°å»ºè®®**ï¼š
â€¢ pvalueé˜ˆå€¼ï¼š0.05ï¼ˆç»Ÿè®¡å­¦æ˜¾è‘—æ€§ï¼‰
â€¢ logFCé˜ˆå€¼ï¼š1.0ï¼ˆç”Ÿç‰©å­¦æ„ä¹‰ï¼Œ2å€å˜åŒ–ï¼‰
â€¢ å»ºè®®ç»“åˆåŠŸèƒ½å¯Œé›†åˆ†æè¿›è¡Œæ·±åº¦è§£è¯»""",

            "ç”Ÿå­˜åˆ†æ": """å¯¹äºç”Ÿå­˜åˆ†æï¼Œæˆ‘æ¨èä½¿ç”¨**FigureYa36nSurvV3**æ¨¡å—ã€‚

ğŸ”¬ **æ–¹æ³•é€‰æ‹©**ï¼š
â€¢ **Kaplan-Meieræ³•**ï¼šé€‚ç”¨äºç”Ÿå­˜æ›²çº¿ä¼°è®¡å’Œæ¯”è¾ƒ
â€¢ **Coxå›å½’æ¨¡å‹**ï¼šç”¨äºå¤šå› ç´ é¢„ååˆ†æ

ğŸ“ˆ **åˆ†æè¦ç‚¹**ï¼š
1. æ•°æ®å‡†å¤‡ï¼šç”Ÿå­˜æ—¶é—´ã€äº‹ä»¶çŠ¶æ€ã€åå˜é‡
2. ç”Ÿå­˜æ›²çº¿ç»˜åˆ¶ï¼šKaplan-Meieræ³•
3. ç»Ÿè®¡æ£€éªŒï¼šLog-rankæ£€éªŒæ¯”è¾ƒç»„é—´å·®å¼‚
4. é£é™©è¯„ä¼°ï¼šè®¡ç®—é£é™©æ¯”(HR)å’Œç½®ä¿¡åŒºé—´

âš ï¸ **æ³¨æ„äº‹é¡¹**ï¼š
â€¢ ç¡®ä¿è¶³å¤Ÿçš„äº‹ä»¶æ•°é‡ï¼ˆå»ºè®®æ¯ç»„â‰¥10ä¸ªäº‹ä»¶ï¼‰
â€¢ æ£€æŸ¥æ¯”ä¾‹é£é™©å‡è®¾
â€¢ è€ƒè™‘æ··æ‚å› ç´ çš„å½±å“""",

            "å•ç»†èƒ": """å•ç»†èƒRNAæµ‹åºåˆ†ææ˜¯ä¸€ä¸ªå¤æ‚çš„å¤šæ­¥éª¤æµç¨‹ï¼Œæ¨èä½¿ç”¨**FigureYa274MuSiCbulkProop**æ¨¡å—ã€‚

ğŸ” **å®Œæ•´åˆ†ææµç¨‹**ï¼š

1. **æ•°æ®è´¨æ§**
   â€¢ ç»†èƒè¿‡æ»¤ï¼šæ’é™¤ä½è´¨é‡ç»†èƒ
   â€¢ åŸºå› è¿‡æ»¤ï¼šæ’é™¤ä½è¡¨è¾¾åŸºå› 
   â€¢ åŒç»†èƒæ£€æµ‹å’Œç§»é™¤

2. **æ ‡å‡†åŒ–å’Œå½’ä¸€åŒ–**
   â€¢ è®¡ç®—æ ‡å‡†åŒ–è¡¨è¾¾å€¼
   â€¢ æ‰¹æ¬¡æ•ˆåº”æ ¡æ­£

3. **ç‰¹å¾é€‰æ‹©å’Œé™ç»´**
   â€¢ é«˜å˜åŸºå› è¯†åˆ«
   â€¢ PCAé™ç»´åˆ†æ
   â€¢ UMAP/tSNEå¯è§†åŒ–

4. **èšç±»åˆ†æ**
   â€¢ ç»†èƒç±»å‹è¯†åˆ«
   â€¢ äºšç¾¤åˆ†æ

5. **å·®å¼‚è¡¨è¾¾åˆ†æ**
   â€¢ ç°·ç¾¤é—´å·®å¼‚åŸºå› è¯†åˆ«
   â€¢ æ ‡è®°åŸºå› ç­›é€‰

ğŸ’¡ **è´¨æ§å…³é”®æŒ‡æ ‡**ï¼š
â€¢ æ¯ä¸ªç»†èƒæ£€æµ‹åˆ°çš„åŸºå› æ•°ï¼ˆ200-6000ä¸ºä½³ï¼‰
â€¢ çº¿ç²’ä½“åŸºå› æ¯”ä¾‹ï¼ˆ<10-15%ï¼‰
â€¢ rRNAæ¯”ä¾‹ï¼ˆ<5%ï¼‰""",

            "PCA": """å¯¹äºPCAåˆ†æï¼Œæˆ‘æ¨èä½¿ç”¨**FigureYa38PCA**æ¨¡å—ã€‚

ğŸ“Š **PCAåˆ†æè¦ç‚¹**ï¼š

1. **æ•°æ®å‡†å¤‡**
   â€¢ æ ‡å‡†åŒ–æ•°æ®ï¼ˆz-scoreæ ‡å‡†åŒ–ï¼‰
   â€¢ å¤„ç†ç¼ºå¤±å€¼
   â€¢ æ£€æŸ¥å¼‚å¸¸å€¼

2. **ä¸»æˆåˆ†é€‰æ‹©**
   â€¢ æŸ¥çœ‹æ–¹å·®è§£é‡Šæ¯”ä¾‹
   â€¢ ä½¿ç”¨è‚˜éƒ¨æ³•åˆ™ç¡®å®šä¸»æˆåˆ†æ•°é‡
   â€¢ é€šå¸¸ä¿ç•™è§£é‡Š85%ä»¥ä¸Šæ–¹å·®çš„ä¸»æˆåˆ†

3. **ç»“æœè§£è¯»**
   â€¢ PC1å’ŒPC2é€šå¸¸è§£é‡Šå¤§éƒ¨åˆ†å˜å¼‚
   â€¢ æ ·æœ¬åœ¨ä¸»æˆåˆ†ç©ºé—´ä¸­çš„åˆ†å¸ƒåæ˜ ç›¸ä¼¼æ€§
   â€¢ è½½è·çŸ©é˜µæ˜¾ç¤ºå˜é‡çš„è´¡çŒ®åº¦

4. **å¯è§†åŒ–**
   â€¢ æ•£ç‚¹å›¾å±•ç¤ºæ ·æœ¬å…³ç³»
   â€¢ è½½è·å›¾å±•ç¤ºå˜é‡é‡è¦æ€§
   â€¢ ç¢çŸ³å›¾æ˜¾ç¤ºä¸»æˆåˆ†é‡è¦æ€§

ğŸ” **åº”ç”¨åœºæ™¯**ï¼š
â€¢ æ•°æ®é™ç»´å’Œå¯è§†åŒ–
â€¢ å¼‚å¸¸å€¼æ£€æµ‹
â€¢ æ ·æœ¬èšç±»åˆ†æ"""
        }

        # æ ¹æ®æŸ¥è¯¢å†…å®¹è¿”å›ç›¸åº”å›ç­”
        for key, response in responses.items():
            if key.lower() in query.lower():
                return response

        # é»˜è®¤å›ç­”
        return f"""åŸºäºæ‚¨çš„æŸ¥è¯¢"{query}"ï¼Œæˆ‘å»ºè®®æ‚¨ï¼š

1. **æ˜ç¡®åˆ†æç›®æ ‡**ï¼šç¡®å®šæ‚¨æƒ³è¦è§£å†³çš„å…·ä½“ç”Ÿç‰©å­¦é—®é¢˜
2. **é€‰æ‹©åˆé€‚æ¨¡å—**ï¼šæ ¹æ®æ•°æ®ç±»å‹é€‰æ‹©ç›¸åº”çš„FigureYaæ¨¡å—
3. **æ•°æ®å‡†å¤‡**ï¼šç¡®ä¿æ•°æ®æ ¼å¼ç¬¦åˆè¦æ±‚ï¼Œè¿›è¡Œå¿…è¦çš„æ•°æ®æ¸…æ´—
4. **å‚æ•°è®¾ç½®**ï¼šæ ¹æ®ç»Ÿè®¡å­¦åŸç†å’Œç”Ÿç‰©å­¦æ„ä¹‰è®¾ç½®åˆé€‚çš„å‚æ•°é˜ˆå€¼
5. **ç»“æœéªŒè¯**ï¼šä½¿ç”¨å¤šç§æ–¹æ³•äº¤å‰éªŒè¯åˆ†æç»“æœçš„å¯é æ€§

ğŸ’¡ å¦‚æœæ‚¨èƒ½æä¾›æ›´å…·ä½“çš„ä¿¡æ¯ï¼ˆå¦‚æ•°æ®ç±»å‹ã€ç ”ç©¶ç›®æ ‡ç­‰ï¼‰ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´ç²¾å‡†çš„å»ºè®®ã€‚

ğŸ” **æ¨èçš„é€šç”¨æ¨¡å—**ï¼š
â€¢ **FigureYa59volcanoV2**ï¼šå·®å¼‚è¡¨è¾¾åˆ†æ
â€¢ **FigureYa38PCA**ï¼šæ•°æ®é™ç»´å’Œå¯è§†åŒ–
â€¢ **FigureYa36nSurvV3**ï¼šç”Ÿå­˜åˆ†æ
â€¢ **FigureYa274MuSiCbulkProop**ï¼šå•ç»†èƒåˆ†æ"""

class MockCompletion:
    def __init__(self, content: str):
        self.choices = [MockChoice(content)]

class MockChoice:
    def __init__(self, content: str):
        self.message = MockMessage(content)

class MockMessage:
    def __init__(self, content: str):
        self.content = content

# å°è¯•å¯¼å…¥çœŸå®çš„æ™ºè°±AI SDK
try:
    from zhipuai import ZhipuAI as RealZhipuAI
    ZhipuAI_AVAILABLE = True
except ImportError:
    ZhipuAI_AVAILABLE = False
    ZhipuAI = MockZhipuAI

@dataclass
class RAGConfig:
    """RAGé…ç½®"""
    api_key: str = ""
    model: str = "glm-4-flash"
    use_mock: bool = not ZhipuAI_AVAILABLE

class FigureYaRAG:
    """FigureYa RAGç³»ç»Ÿ"""

    def __init__(self, config: RAGConfig):
        self.config = config
        self.knowledge_base = self._build_knowledge_base()

        # åˆå§‹åŒ–AIå®¢æˆ·ç«¯
        if config.use_mock:
            self.client = MockZhipuAI(config.api_key)
        else:
            try:
                self.client = RealZhipuAI(api_key=config.api_key)
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆå§‹åŒ–æ™ºè°±AI: {e}")
                self.client = MockZhipuAI(config.api_key)

    def _build_knowledge_base(self) -> dict:
        """æ„å»ºçŸ¥è¯†åº“"""
        return {
            "å·®å¼‚è¡¨è¾¾åˆ†æ": {
                "modules": ["FigureYa59volcanoV2", "FigureYa9heatmap"],
                "description": "è¯†åˆ«ä¸åŒæ¡ä»¶é—´åŸºå› è¡¨è¾¾å·®å¼‚",
                "methods": ["DESeq2", "edgeR", "limma"],
                "keywords": ["RNA-seq", "å·®å¼‚åŸºå› ", "ç«å±±å›¾", "çƒ­å›¾"]
            },
            "ç”Ÿå­˜åˆ†æ": {
                "modules": ["FigureYa36nSurvV3", "FigureYa1survivalCurve_update"],
                "description": "åˆ†ææ‚£è€…ç”Ÿå­˜æ—¶é—´å’Œå½±å“å› ç´ ",
                "methods": ["Kaplan-Meier", "Coxå›å½’"],
                "keywords": ["ç”Ÿå­˜", "é¢„å", "é£é™©æ¯”", "Kaplan-Meier"]
            },
            "å•ç»†èƒåˆ†æ": {
                "modules": ["FigureYa274MuSiCbulkProop", "FigureYa243scMarkerGroupHeatmap"],
                "description": "å•ä¸ªç»†èƒæ°´å¹³çš„åŸºå› è¡¨è¾¾åˆ†æ",
                "methods": ["è´¨æ§", "é™ç»´", "èšç±»", "å·®å¼‚åˆ†æ"],
                "keywords": ["å•ç»†èƒ", "scRNA-seq", "UMAP", "tSNE", "èšç±»"]
            },
            "PCAåˆ†æ": {
                "modules": ["FigureYa38PCA", "FigureYa164PCA3D"],
                "description": "é«˜ç»´æ•°æ®çš„é™ç»´å’Œå¯è§†åŒ–",
                "methods": ["ä¸»æˆåˆ†åˆ†æ", "å¥‡å¼‚å€¼åˆ†è§£"],
                "keywords": ["PCA", "ä¸»æˆåˆ†", "é™ç»´", "å¯è§†åŒ–"]
            }
        }

    def intelligent_search(self, query: str) -> dict:
        """æ™ºèƒ½æœç´¢å’Œå›ç­”"""
        try:
            # æ£€ç´¢ç›¸å…³çŸ¥è¯†
            relevant_info = self._retrieve_knowledge(query)

            # ç”Ÿæˆæ™ºèƒ½å›ç­”
            response = self._generate_ai_response(query, relevant_info)

            return {
                "query": query,
                "response": response,
                "sources": [info.get("modules", []) for info in relevant_info],
                "model": self.config.model,
                "ai_enhanced": True,
                "use_mock": self.config.use_mock
            }

        except Exception as e:
            return {
                "query": query,
                "response": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "sources": [],
                "model": self.config.model,
                "ai_enhanced": False,
                "error": str(e)
            }

    def _retrieve_knowledge(self, query: str) -> List[dict]:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        query_lower = query.lower()
        relevant = []

        for topic, info in self.knowledge_base.items():
            score = 0

            # å…³é”®è¯åŒ¹é…
            for keyword in info.get("keywords", []):
                if keyword.lower() in query_lower:
                    score += 2

            # æ–¹æ³•åŒ¹é…
            for method in info.get("methods", []):
                if method.lower() in query_lower:
                    score += 3

            # æ¨¡å—åŒ¹é…
            for module in info.get("modules", []):
                if module.lower() in query_lower:
                    score += 1

            if score > 0:
                relevant.append({"topic": topic, **info, "score": score})

        # æŒ‰åˆ†æ•°æ’åº
        relevant.sort(key=lambda x: x["score"], reverse=True)
        return relevant[:3]

    def _generate_ai_response(self, query: str, relevant_info: List[dict]) -> str:
        """ä½¿ç”¨AIç”Ÿæˆå›ç­”"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”Ÿç‰©åŒ»å­¦æ•°æ®åˆ†æä¸“å®¶ï¼ŒåŸºäºFigureYaçŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

è¯·æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸“ä¸šã€å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ã€‚è¦æ±‚ï¼š
1. åŸºäºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šå»ºè®®
2. ç»™å‡ºå…·ä½“çš„åˆ†ææ­¥éª¤å’Œå‚æ•°å»ºè®®
3. ä½¿ç”¨ä¸­æ–‡å›ç­”
4. ä¿æŒä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­æ°”"""
                },
                {
                    "role": "user",
                    "content": query
                }
            ]

            # å¦‚æœæ˜¯çœŸå®API
            if not self.config.use_mock:
                response = self.client.chat.completions.create(
                    model=self.config.model,
                    messages=messages,
                    max_tokens=800,
                    temperature=0.7
                )
                return response.choices[0].message.content
            else:
                # ä½¿ç”¨æ¨¡æ‹ŸAPI
                return self.client.chat(messages).choices[0].message.content

        except Exception as e:
            print(f"âš ï¸ AI APIè°ƒç”¨å¤±è´¥: {e}")
            return self._fallback_response(query, relevant_info)

    def _fallback_response(self, query: str, relevant_info: List[dict]) -> str:
        """å¤‡ç”¨å›ç­”"""
        if relevant_info:
            best = relevant_info[0]
            return f"""åŸºäºæ‚¨çš„æŸ¥è¯¢ï¼Œæˆ‘æ¨èä»¥ä¸‹æ¨¡å—ï¼š

ğŸ¯ **æ¨èæ¨¡å—**: {', '.join(best['modules'])}
ğŸ“ **åŠŸèƒ½æè¿°**: {best['description']}
ğŸ”¬ **æŠ€æœ¯æ–¹æ³•**: {', '.join(best['methods'])}

ğŸ’¡ è¿™æ˜¯ä¸€ä¸ªåŸºç¡€çš„æ¨èç»“æœã€‚å¦‚éœ€æ›´ä¸“ä¸šçš„ä¸ªæ€§åŒ–å»ºè®®ï¼Œå»ºè®®é…ç½®æ™ºè°±AI APIå¯†é’¥ã€‚"""

        return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•ä½¿ç”¨æ›´å…·ä½“çš„å…³é”®è¯ã€‚"

class RAGAPIHandler(BaseHTTPRequestHandler):
    """RAG APIå¤„ç†å™¨"""

    def __init__(self, *args, rag_system=None, **kwargs):
        self.rag_system = rag_system
        super().__init__(*args, **kwargs)

    def do_GET(self):
        """å¤„ç†GETè¯·æ±‚"""
        if self.path == '/' or self.path == '/index.html':
            self.serve_file('figureya_ai_search.html')
        elif self.path == '/api/status':
            self.handle_status()
        elif self.path.startswith('/api/search'):
            self.handle_search()
        else:
            self.serve_static_file(self.path[1:])

    def do_POST(self):
        """å¤„ç†POSTè¯·æ±‚"""
        if self.path == '/api/chat':
            self.handle_chat()
        else:
            self.send_error(404)

    def handle_status(self):
        """å¤„ç†çŠ¶æ€æŸ¥è¯¢"""
        try:
            status_data = {
                "status": "ready",
                "service": "FigureYa AI RAG",
                "version": "1.0.0",
                "model": "GLM-4-Flash",
                "features": [
                    "æ™ºèƒ½æœç´¢",
                    "ä¸“ä¸šåˆ†æå»ºè®®",
                    "æ¨¡å—æ¨è",
                    "å‚æ•°æŒ‡å¯¼"
                ],
                "knowledge_base_size": len(self.rag_system.knowledge_base) if self.rag_system else 0,
                "use_mock": self.rag_system.config.use_mock if self.rag_system else True
            }
            self.send_json_response(status_data)
        except Exception as e:
            self.send_json_response({"error": str(e)}, 500)

    def handle_search(self):
        """å¤„ç†æœç´¢è¯·æ±‚"""
        try:
            parsed_url = urllib.parse.urlparse(self.path)
            query_params = urllib.parse.parse_qs(parsed_url.query)
            query = query_params.get('q', [''])[0]

            if not query.strip():
                self.send_json_response({"error": "Empty query"}, 400)
                return

            if not self.rag_system:
                self.send_json_response({"error": "RAG system not initialized"}, 503)
                return

            result = self.rag_system.intelligent_search(query)
            self.send_json_response(result)

        except Exception as e:
            self.send_json_response({"error": str(e)}, 500)

    def handle_chat(self):
        """å¤„ç†èŠå¤©è¯·æ±‚"""
        try:
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length == 0:
                self.send_json_response({"error": "No data received"}, 400)
                return

            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            query = data.get('message', '').strip()

            if not query:
                self.send_json_response({"error": "Empty message"}, 400)
                return

            if not self.rag_system:
                self.send_json_response({"error": "RAG system not initialized"}, 503)
                return

            result = self.rag_system.intelligent_search(query)
            self.send_json_response(result)

        except json.JSONDecodeError:
            self.send_json_response({"error": "Invalid JSON"}, 400)
        except Exception as e:
            self.send_json_response({"error": str(e)}, 500)

    def serve_file(self, filename):
        """æä¾›æ–‡ä»¶æœåŠ¡"""
        try:
            file_path = Path(__file__).parent / filename
            if not file_path.exists():
                self.send_error(404)
                return

            with open(file_path, 'rb') as f:
                content = f.read()

            self.send_response(200)
            self.send_header('Content-type', self.get_content_type(filename))
            self.send_header('Content-Length', str(len(content)))
            self.end_headers()
            self.wfile.write(content)

        except Exception as e:
            self.send_error(500)

    def serve_static_file(self, filename):
        """æä¾›é™æ€æ–‡ä»¶æœåŠ¡"""
        try:
            file_path = Path(__file__).parent / filename
            if not file_path.exists():
                self.send_error(404)
                return

            with open(file_path, 'rb') as f:
                content = f.read()

            self.send_response(200)
            self.send_header('Content-type', self.get_content_type(filename))
            self.send_header('Cache-Control', 'public, max-age=3600')
            self.end_headers()
            self.wfile.write(content)

        except Exception:
            self.send_error(404)

    def send_json_response(self, data, status=200):
        """å‘é€JSONå“åº”"""
        try:
            response_json = json.dumps(data, ensure_ascii=False, indent=2)
            self.send_response(status)
            self.send_header('Content-type', 'application/json; charset=utf-8')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'GET, POST, OPTIONS')
            self.send_header('Access-Control-Allow-Headers', 'Content-Type')
            self.end_headers()
            self.wfile.write(response_json.encode('utf-8'))
        except Exception as e:
            print(f"Error sending JSON response: {e}")

    def get_content_type(self, filename):
        """è·å–æ–‡ä»¶å†…å®¹ç±»å‹"""
        content_types = {
            '.html': 'text/html; charset=utf-8',
            '.css': 'text/css',
            '.js': 'application/javascript',
            '.json': 'application/json',
            '.png': 'image/png',
            '.jpg': 'image/jpeg',
            '.gif': 'image/gif',
            '.svg': 'image/svg+xml'
        }

        ext = Path(filename).suffix.lower()
        return content_types.get(ext, 'application/octet-stream')

    def log_message(self, format, *args):
        """å‡å°‘æ—¥å¿—è¾“å‡º"""
        pass

def create_handler_class(rag_system):
    """åˆ›å»ºå¤„ç†å™¨ç±»"""
    class Handler(RAGAPIHandler):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, rag_system=rag_system, **kwargs)
    return Handler

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='FigureYa AI RAG Server')
    parser.add_argument('--host', default='localhost', help='æœåŠ¡å™¨åœ°å€')
    parser.add_argument('--port', type=int, default=8080, help='æœåŠ¡å™¨ç«¯å£')
    parser.add_argument('--api-key', help='æ™ºè°±AI APIå¯†é’¥')
    parser.add_argument('--mock', action='store_true', help='ä½¿ç”¨æ¨¡æ‹ŸAPI')

    args = parser.parse_args()

    print("ğŸ§  FigureYa AI RAG æœåŠ¡å™¨")
    print("=" * 40)

    # åŠ è½½APIå¯†é’¥
    api_key = args.api_key or os.getenv("ZHIPUAI_API_KEY")
    if not api_key and not args.mock:
        print("âš ï¸ æœªæ‰¾åˆ°æ™ºè°±AI APIå¯†é’¥")
        print("ğŸ’¡ ä½¿ç”¨æ¨¡æ‹ŸAPIæ¨¡å¼")
        api_key = "mock-key"

    # åˆå§‹åŒ–é…ç½®
    config = RAGConfig(
        api_key=api_key,
        use_mock=args.mock or (not api_key or api_key == "mock-key")
    )

    # åˆå§‹åŒ–RAGç³»ç»Ÿ
    rag_system = FigureYaRAG(config)

    print(f"ğŸ¤– AIæ¨¡å‹: {config.model}")
    print(f"ğŸ”§ æ¨¡æ‹Ÿæ¨¡å¼: {'æ˜¯' if config.use_mock else 'å¦'}")
    print(f"ğŸ“š çŸ¥è¯†åº“å¤§å°: {len(rag_system.knowledge_base)} ä¸ªä¸»é¢˜")

    # åˆ›å»ºHTTPæœåŠ¡å™¨
    handler_class = create_handler_class(rag_system)
    server = HTTPServer((args.host, args.port), handler_class)

    print(f"ğŸš€ æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")
    print(f"ğŸŒ è®¿é—®åœ°å€: http://{args.host}:{args.port}")
    print(f"ğŸ“Š APIçŠ¶æ€: http://{args.host}:{args.port}/api/status")
    print(f"ğŸ” æœç´¢API: http://{args.host}:{args.port}/api/search?q=RNA-seq")
    print("ğŸ›‘ æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
    print("-" * 50)

    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")

if __name__ == "__main__":
    main()