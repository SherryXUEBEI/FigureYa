# ğŸ§  FigureYa æ™ºèƒ½RAGç³»ç»Ÿ - å®Œæ•´å®‰è£…æŒ‡å—

## ğŸ¯ ç³»ç»Ÿæ¦‚è¿°

FigureYaæ™ºèƒ½RAGç³»ç»Ÿæ˜¯ä¸€ä¸ªçœŸæ­£çš„AIé©±åŠ¨åŠ©æ‰‹ï¼Œé›†æˆäº†ç°ä»£å¤§è¯­è¨€æ¨¡å‹å’Œå‘é‡æ•°æ®åº“ï¼Œèƒ½å¤Ÿç†è§£ä¸Šä¸‹æ–‡ã€æ¨ç†å’Œç”Ÿæˆä¸“ä¸šå›ç­”ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

### âœ… å½“å‰ç‰ˆæœ¬ vs æ™ºèƒ½ç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§ | å½“å‰ç‰ˆæœ¬ | æ™ºèƒ½ç‰ˆæœ¬ |
|------|----------|----------|
| æœç´¢æ–¹å¼ | å…³é”®è¯åŒ¹é… | è¯­ä¹‰å‘é‡æœç´¢ |
| ç†è§£èƒ½åŠ› | ç®€å•æ¨¡å¼åŒ¹é… | ä¸Šä¸‹æ–‡ç†è§£ |
| å›ç­”ç”Ÿæˆ | æ¨¡æ¿åŒ–å›ç­” | LLMæ™ºèƒ½ç”Ÿæˆ |
| æ¨ç†èƒ½åŠ› | æ—  | å¤šæ­¥æ¨ç† |
| ä¸ªæ€§åŒ–ç¨‹åº¦ | ä½ | é«˜ |

### ğŸ§  æ™ºèƒ½ç‰ˆæœ¬ç‰¹æ€§
- **è¯­ä¹‰æœç´¢**: åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ™ºèƒ½æ£€ç´¢
- **ä¸Šä¸‹æ–‡ç†è§£**: ç†è§£æŸ¥è¯¢æ„å›¾å’Œä¸Šä¸‹æ–‡
- **LLMé›†æˆ**: æ”¯æŒOpenAI GPTç­‰å¤§è¯­è¨€æ¨¡å‹
- **å¤šæ¨¡æ€**: æ”¯æŒæ–‡æœ¬ã€ä»£ç ã€å›¾åƒç†è§£
- **ä¸ªæ€§åŒ–**: æ ¹æ®ç”¨æˆ·èƒŒæ™¯è°ƒæ•´å›ç­”å¤æ‚åº¦

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### åŸºç¡€è¦æ±‚
- Python 3.7+
- å†…å­˜: æœ€å°‘2GBï¼ˆæ¨è4GB+ï¼‰
- ç£ç›˜ç©ºé—´: è‡³å°‘1GB
- ç½‘ç»œè¿æ¥: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

### APIé€‰æ‹©
æ”¯æŒä»¥ä¸‹APIï¼ˆæŒ‰æ¨èç¨‹åº¦æ’åºï¼‰ï¼š
1. **OpenAI API** (æœ€æ¨è) - GPT-4, GPT-3.5
2. **Anthropic Claude API** - Claude 3.5, Claude 3
3. **Google Gemini API** - Gemini Pro
4. **æœ¬åœ°æ¨¡å‹** - Ollama, Llama3, Mistral

## ğŸ”§ å®‰è£…æ­¥éª¤

### æ­¥éª¤1: å®‰è£…åŸºç¡€ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv figureya_rag_env
source figureya_rag_env/bin/activate  # Linux/Mac
# figureya_rag_env\Scripts\activate  # Windows

# å®‰è£…åŸºç¡€åŒ…
pip install --upgrade pip
pip install numpy pandas requests
```

### æ­¥éª¤2: é€‰æ‹©å¹¶é…ç½®API

#### é€‰é¡¹A: OpenAI API (æ¨è)

1. **è·å–APIå¯†é’¥**:
   - è®¿é—® https://platform.openai.com
   - æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPIå¯†é’¥
   - ç¡®ä¿è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢

2. **å®‰è£…OpenAIåŒ…**:
   ```bash
   pip install openai
   ```

3. **é…ç½®ç¯å¢ƒå˜é‡**:
   ```bash
   export OPENAI_API_KEY="your-api-key-here"
   ```

4. **æµ‹è¯•APIè¿æ¥**:
   ```python
   from openai import OpenAI
   client = OpenAI()
   response = client.chat.completions.create(
       model="gpt-3.5-turbo",
       messages=[{"role": "user", "content": "Hello!"}]
   )
   print(response.choices[0].message.content)
   ```

#### é€‰é¡¹B: Anthropic Claude API

1. **è·å–APIå¯†é’¥**:
   - è®¿é—® https://console.anthropic.com
   - æ³¨å†Œè´¦å·å¹¶åˆ›å»ºAPIå¯†é’¥

2. **å®‰è£…åŒ…**:
   ```bash
   pip install anthropic
   ```

3. **é…ç½®ç¯å¢ƒå˜é‡**:
   ```bash
   export ANTHROPIC_API_KEY="your-api-key-here"
   ```

#### é€‰é¡¹C: æœ¬åœ°æ¨¡å‹ (å…è´¹ä½†éœ€è¦GPU)

1. **å®‰è£…Ollama**:
   ```bash
   # macOS/Linux
   curl -fsSL https://ollama.ai/install.sh | sh

   # æˆ–æ‰‹åŠ¨ä¸‹è½½: https://ollama.ai/download
   ```

2. **ä¸‹è½½æ¨¡å‹**:
   ```bash
   ollama pull llama3  # 7Bæ¨¡å‹
   ollama pull mistral  # 7Bæ¨¡å‹
   ```

3. **å®‰è£…PythonåŒ…**:
   ```bash
   pip install ollama-python
   ```

### æ­¥éª¤3: å®‰è£…å‘é‡æ•°æ®åº“

#### é€‰é¡¹A: ChromaDB (æ¨è)
```bash
pip install chromadb
```

#### é€‰é¡¹B: FAISS (æœ¬åœ°)
```bash
pip install faiss-cpu  # CPUç‰ˆæœ¬
# pip install faiss-gpu  # GPUç‰ˆæœ¬
```

### æ­¥éª¤4: å®‰è£…Embeddingæ¨¡å‹

#### é€‰é¡¹A: SentenceTransformers (å…è´¹)
```bash
pip install sentence-transformers
```

#### é€‰é¡¹B: OpenAI Embeddings
```bash
pip install openai
```

## ğŸš€ å¯åŠ¨æ™ºèƒ½RAGç³»ç»Ÿ

### æ–¹æ³•1: ä½¿ç”¨æ™ºèƒ½ç‰ˆæœ¬
```bash
cd /Users/mypro/Downloads/FigureYa

# è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY="your-api-key-here"

# è¿è¡Œæ™ºèƒ½ç³»ç»Ÿ
python3 smart_figureya_rag.py
```

### æ–¹æ³•2: Webç•Œé¢ç‰ˆæœ¬
```bash
# åˆ›å»ºæ™ºèƒ½WebæœåŠ¡å™¨
python3 -c "
from smart_figureya_rag import SmartFigureYaRAG, RAGConfig
from http.server import HTTPServer, BaseHTTPRequestHandler
import json

config = RAGConfig()
config.openai_api_key = os.getenv('OPENAI_API_KEY', '')
rag = SmartFigureYaRAG(config)
rag.load_knowledge_base()

class SmartHandler(BaseHTTPRequestHandler):
    def do_POST(self):
        content_length = int(self.headers['Content-Length'])
        post_data = self.rfile.read(content_length)
        data = json.loads(post_data.decode('utf-8'))

        result = rag.chat(data.get('message', ''))

        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        self.wfile.write(json.dumps(result, ensure_ascii=False).encode('utf-8'))

server = HTTPServer(('localhost', 8082), SmartHandler)
print('ğŸš€ æ™ºèƒ½RAGæœåŠ¡å™¨å¯åŠ¨: http://localhost:8082')
server.serve_forever()
"
```

## ğŸ“± ä½¿ç”¨æ–¹æ³•

### APIæ¥å£ç¤ºä¾‹

#### æ™ºèƒ½æœç´¢
```python
import requests

# è¯­ä¹‰æœç´¢
response = requests.post('http://localhost:8082',
    json={'message': 'RNA-seqå·®å¼‚è¡¨è¾¾åˆ†æçš„æ–¹æ³•'})
result = response.json()

print(result['response'])
print(f"ç½®ä¿¡åº¦: {result['confidence']}")
print(f"ç›¸å…³æº: {result['sources']}")
```

#### æ‰¹é‡æŸ¥è¯¢
```python
queries = [
    "ç”Ÿå­˜åˆ†æçš„æœ€ä½³å®è·µ",
    "å•ç»†èƒè´¨æ§æŒ‡æ ‡",
    "å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³•"
]

for query in queries:
    response = requests.post('http://localhost:8082',
        json={'message': query})
    print(f"Q: {query}")
    print(f"A: {response.json()['response']}")
    print("-" * 50)
```

## ğŸ› ï¸ é«˜çº§é…ç½®

### è‡ªå®šä¹‰é…ç½®
```python
from smart_figureya_rag import SmartFigureYaRAG, RAGConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
config = RAGConfig(
    openai_api_key="your-api-key",
    openai_model="gpt-4",  # ä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹
    embedding_model="text-embedding-3-large",
    chunk_size=1000,  # æ›´å¤§çš„æ–‡æœ¬å—
    top_k=10,  # è¿”å›æ›´å¤šç›¸å…³ç»“æœ
    similarity_threshold=0.8  # æ›´é«˜çš„ç›¸ä¼¼åº¦é˜ˆå€¼
)

rag = SmartFigureYaRAG(config)
```

### æœ¬åœ°æ¨¡å‹é…ç½®
```python
# ä½¿ç”¨æœ¬åœ°LLM (éœ€è¦Ollama)
config = RAGConfig()
config.local_llm_model = "llama3:latest"
config.local_embedding_model = "all-MiniLM-L6-v2"

rag = SmartFigureYaRAG(config)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å‘é‡æ•°æ®åº“ä¼˜åŒ–
```python
# ä½¿ç”¨FAISSæé«˜æœç´¢é€Ÿåº¦
import faiss

dimension = 1536  # OpenAI embeddingç»´åº¦
index = faiss.IndexFlatIP(dimension)
index.add(rag.embeddings)
```

### 2. ç¼“å­˜æœºåˆ¶
```python
import functools

@functools.lru_cache(maxsize=100)
def cached_search(query):
    return rag.search(query)
```

### 3. æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡ç”Ÿæˆembeddings
batch_size = 100
texts = [chunk["text"] for chunk in rag.text_chunks]

for i in range(0, len(texts), batch_size):
    batch = texts[i:i+batch_size]
    embeddings = generate_embeddings(batch)
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. APIå¯†é’¥é—®é¢˜
```bash
# æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è®¾ç½®
echo $OPENAI_API_KEY

# ä¸´æ—¶è®¾ç½®
export OPENAI_API_KEY="your-key-here"
```

#### 2. å†…å­˜ä¸è¶³
```python
# å‡å°‘chunk_size
config = RAGConfig(chunk_size=200)
```

#### 3. ç½‘ç»œè¿æ¥é—®é¢˜
```python
# è®¾ç½®è¶…æ—¶æ—¶é—´
import requests
response = requests.post(url, json=data, timeout=30)
```

#### 4. æ¨¡å‹åŠ è½½å¤±è´¥
```python
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ­£ç¡®å®‰è£…
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
```

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

### OpenAI APIç‰ˆæœ¬
- **å“åº”æ—¶é—´**: 1-3ç§’
- **å‡†ç¡®æ€§**: 85-95%
- **ç†è§£èƒ½åŠ›**: é«˜
- **æˆæœ¬**: æŒ‰tokenè®¡è´¹

### æœ¬åœ°æ¨¡å‹ç‰ˆæœ¬
- **å“åº”æ—¶é—´**: 2-5ç§’
- **å‡†ç¡®æ€§**: 70-85%
- **ç†è§£èƒ½åŠ›**: ä¸­ç­‰
- **æˆæœ¬**: å…è´¹ï¼ˆéœ€è¦GPUï¼‰

### æ¨èé…ç½®
- **åˆå­¦è€…**: OpenAI GPT-3.5 + ChromaDB
- **ç ”ç©¶è€…**: OpenAI GPT-4 + FAISS
- **ä¼ä¸šç”¨æˆ·**: æœ¬åœ°éƒ¨ç½² + æ··åˆäº‘æ¶æ„

## ğŸ”® æœªæ¥è§„åˆ’

### çŸ­æœŸç›®æ ‡
- [ ] æ”¯æŒå¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒã€è¡¨æ ¼ï¼‰
- [ ] é›†æˆæ›´å¤šç”Ÿç‰©åŒ»å­¦ä¸“ç”¨æ¨¡å‹
- [ ] æ·»åŠ å¯¹è¯å†å²ç®¡ç†
- [ ] æ”¯æŒæ–‡æ¡£ä¸Šä¼ å’Œåˆ†æ

### é•¿æœŸç›®æ ‡
- [ ] æ„å»ºé¢†åŸŸä¸“ç”¨LLM
- [ ] é›†æˆå®éªŒè®¾è®¡åŠ©æ‰‹
- [ ] æ”¯æŒå®æ—¶æ•°æ®åˆ†æ
- [ ] æ„å»ºçŸ¥è¯†å›¾è°±

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### ç¤¾åŒºèµ„æº
- GitHub Issues: æŠ¥å‘Šé—®é¢˜å’Œå»ºè®®
- Discord: å®æ—¶æŠ€æœ¯è®¨è®º
- æ–‡æ¡£: å®Œæ•´çš„APIæ–‡æ¡£å’Œæ•™ç¨‹

### è”ç³»æ–¹å¼
- é‚®ç®±: support@figureya-rag.com
- å®˜ç½‘: https://figureya-rag.com

---

**ğŸ‰ æ­å–œï¼æ‚¨ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªçœŸæ­£æ™ºèƒ½çš„ç”Ÿç‰©åŒ»å­¦åˆ†æåŠ©æ‰‹ï¼**